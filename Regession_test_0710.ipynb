{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMCHKi3cweR+4xOZeitZfKA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dolmani38/non-linear-regression/blob/master/Regession_test_0710.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKtp6QcEcGnL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "3765e3fe-ddc2-4764-c370-1bcf447d2d39"
      },
      "source": [
        "!pip install lime\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, BatchNormalization\n",
        "from keras.layers import Input, Embedding, Dense\n",
        "from keras.models import Model\n",
        "from keras.callbacks import Callback\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from lime import lime_tabular, lime_text\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Bayesian Methods for Hackers style sheet\n",
        "plt.style.use('bmh')\n",
        "\n",
        "np.random.seed(1234567890)\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def r2(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    # custom R2-score metrics for keras backend\n",
        "    :param y_true: 실측 데이터\n",
        "    :param y_pred: 모델에 의한 예측 데이테\n",
        "    :return: R^2 value, 이 값이 높다고 (예:0.99)해서 예측 값이 정확 하다고 할 수 는 없음...\n",
        "    \"\"\"\n",
        "    SS_res = K.sum(K.square(y_true - y_pred))\n",
        "    SS_tot = K.sum(K.square(y_true - K.mean(y_true)))\n",
        "    return (1 - SS_res / (SS_tot + K.epsilon()))\n",
        "\n",
        "def soft_100_acc(y_true, y_pred):\n",
        "    delta = 100\n",
        "    return K.mean(K.less_equal(K.abs(y_true-y_pred),delta))\n",
        "\n",
        "def soft_300_acc(y_true, y_pred):\n",
        "    delta = 300\n",
        "    return K.mean(K.less_equal(K.abs(y_true-y_pred),delta))\n",
        "\n",
        "def structure(df):\n",
        "    \"\"\"\n",
        "    DataFrame의 column 등 전반적인 구조를 표출 한다.\n",
        "    :param df:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    df1 = df.describe(include='all').T\n",
        "    df1['type'] = df.dtypes\n",
        "    df1['null count'] = df.isnull().sum()\n",
        "    if 'freq' in df1.columns:\n",
        "        df2 = df1[\n",
        "            ['type', 'count', 'null count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'unique', 'top',\n",
        "             'freq']]\n",
        "    else:\n",
        "        df2 = df1[['type', 'count', 'null count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max']]\n",
        "\n",
        "    return df2\n",
        "\n",
        "class VerboseCallback(keras.callbacks.Callback):\n",
        "    \"\"\"\n",
        "    kerase.model.fit 함수에서, log 출력을 위한 callback\n",
        "    \"\"\"\n",
        "    def __init__(self, epoch):\n",
        "        self.epoch = epoch\n",
        "        self.progress(\"learning:\", 0, [])\n",
        "\n",
        "    def progress(self, text, current=0, log=None):\n",
        "        g = self.epoch - current\n",
        "        f = 50 / self.epoch\n",
        "        c = int(current * f)\n",
        "        pg = ['=' for i in range(c)] + ['.' for i in range(50 - c)]\n",
        "        print(\"\\r\" + str(text) + \"{}/{}[{}]{}\".format(current, self.epoch, ''.join(pg), ('' if log is None else str(log).strip())),\n",
        "              end=\"\", flush=True)\n",
        "        if self.epoch - current == 0:\n",
        "            print(\"\")\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.progress(\"learning:\", epoch + 1, logs)\n",
        "\n",
        "\n",
        "class PeriodicLogger(Callback):\n",
        "    \"\"\"\n",
        "    A helper callback class that only prints the losses once in 'display' epochs\n",
        "    \"\"\"\n",
        "    def __init__(self, display=100):\n",
        "        self.display = display\n",
        "\n",
        "    def on_train_begin(self, logs={}):      \n",
        "        self.epochs = 0    \n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):    \n",
        "        self.epochs += 1     \n",
        "        if self.epochs % self.display == 0:\n",
        "            print (\"Epoch: %d - %s\" % (self.epochs, str(logs)))\n",
        " \n",
        "periodic_logger_50 = PeriodicLogger(50)\n",
        "periodic_logger_250 = PeriodicLogger(250)\n",
        "periodic_logger_1000 = PeriodicLogger(1000)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.15.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (7.0.0)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.12.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp36-none-any.whl size=283845 sha256=1d5936a3f0f8eecdd23017debc4397333d312e56395d690813ffdf201330d469\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0hfL8Y8cUL_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "per_meter_mapping = {\n",
        "    'Mercaz': 500,\n",
        "    'Old North': 350,\n",
        "    'Florentine': 230\n",
        "}\n",
        "\n",
        "per_room_additional_price = {\n",
        "    'Mercaz': 15. * 10**4,\n",
        "    'Old North': 8. * 10**4,\n",
        "    'Florentine': 5. * 10**4\n",
        "}\n",
        "\n",
        "per_type_price = {\n",
        "    'fullsize': 3,\n",
        "    'economy': 1.2,\n",
        "    'convertible': 9,\n",
        "    'standard': 2.5,\n",
        "    'premium': 4,\n",
        "    'intermediate': 2,\n",
        "    'luxury': 12,\n",
        "    'compact': 1.5\n",
        "}\n",
        "\n",
        "def house_price_func(row):\n",
        "    \"\"\"\n",
        "    house_price_func is the function f(a,s,n).\n",
        "    \n",
        "    :param row: dict (contains the keys: ['area', 'size', 'n_rooms'])\n",
        "    :return: float\n",
        "    \"\"\"\n",
        "    area, size, n_rooms, ctype = row['area'], row['size'], row['n_rooms'], row['ctype']\n",
        "    return (size * per_meter_mapping[area] - 120) + (n_rooms*n_rooms)/4 * per_room_additional_price[area] * per_type_price[ctype]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGFmtjnhcXeN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "AREAS = ['Mercaz', 'Old North', 'Florentine']\n",
        "HOUSE_TYPE = ['economy','compact','intermediate','standard','fullsize','premium','luxury','convertible']\n",
        "\n",
        "def create_samples(n_samples):\n",
        "    \"\"\"\n",
        "    Helper method that creates dataset DataFrames\n",
        "    \n",
        "    Note that the np.random.choice call only determines the number of rooms and the size of the house\n",
        "    (the price, which we calculate later, is deterministic)\n",
        "    \n",
        "    :param n_samples: int (number of samples for each area (suburb))\n",
        "    :return: pd.DataFrame\n",
        "    \"\"\"\n",
        "    samples = []\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        samples.append([np.random.choice(AREAS), int(np.random.normal(25, 5)),int(np.random.normal(300, 50)), np.random.choice(range(1, 6)),np.random.choice(HOUSE_TYPE)])\n",
        "        \n",
        "    return pd.DataFrame(samples, columns=['area', 'size', 'lamp', 'n_rooms','ctype'])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_3K76f0cbvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = create_samples(n_samples=10000)\n",
        "dataset['price'] = dataset.apply(house_price_func, axis=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dN34-Z-_ceAU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "149f7e1c-8c04-4ec2-9535-bc05e9a9ea99"
      },
      "source": [
        "structure(dataset)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>count</th>\n",
              "      <th>null count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>area</th>\n",
              "      <td>object</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3</td>\n",
              "      <td>Florentine</td>\n",
              "      <td>3383</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>size</th>\n",
              "      <td>int64</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>24.3777</td>\n",
              "      <td>5.04753</td>\n",
              "      <td>7</td>\n",
              "      <td>21</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>46</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lamp</th>\n",
              "      <td>int64</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>298.422</td>\n",
              "      <td>49.942</td>\n",
              "      <td>118</td>\n",
              "      <td>265</td>\n",
              "      <td>298</td>\n",
              "      <td>331</td>\n",
              "      <td>525</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>n_rooms</th>\n",
              "      <td>int64</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>2.9976</td>\n",
              "      <td>1.42401</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ctype</th>\n",
              "      <td>object</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>intermediate</td>\n",
              "      <td>1295</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>float64</td>\n",
              "      <td>10000</td>\n",
              "      <td>0</td>\n",
              "      <td>1.12174e+06</td>\n",
              "      <td>1.67661e+06</td>\n",
              "      <td>17640</td>\n",
              "      <td>170448</td>\n",
              "      <td>488630</td>\n",
              "      <td>1.29143e+06</td>\n",
              "      <td>1.12674e+07</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            type  count  null count  ... unique           top  freq\n",
              "area      object  10000           0  ...      3    Florentine  3383\n",
              "size       int64  10000           0  ...    NaN           NaN   NaN\n",
              "lamp       int64  10000           0  ...    NaN           NaN   NaN\n",
              "n_rooms    int64  10000           0  ...    NaN           NaN   NaN\n",
              "ctype     object  10000           0  ...      8  intermediate  1295\n",
              "price    float64  10000           0  ...    NaN           NaN   NaN\n",
              "\n",
              "[6 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__WXQGyscfE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dataset의 파생변수 생성\n",
        "\n",
        "dataset['size_n_rooms'] = dataset['size'] * dataset['n_rooms']\n",
        "dataset['size_size'] = dataset['size'] * dataset['size']\n",
        "dataset['n_rooms_n_rooms'] = dataset['n_rooms'] * dataset['n_rooms']"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXqTnmMbchLR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "6c3456c7-7c02-4a7a-cbf9-dbfa67d481aa"
      },
      "source": [
        "# zscore norm\n",
        "\n",
        "ds = dataset[['size','lamp','n_rooms','size_n_rooms','size_size','n_rooms_n_rooms']]\n",
        "\n",
        "_mean = ds.mean(axis=0)\n",
        "_std = ds.std(axis=0)\n",
        "\n",
        "ds = ds - _mean\n",
        "ds /= _std\n",
        "\n",
        "dataset.update(ds)\n",
        "dataset"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>size</th>\n",
              "      <th>lamp</th>\n",
              "      <th>n_rooms</th>\n",
              "      <th>ctype</th>\n",
              "      <th>price</th>\n",
              "      <th>size_n_rooms</th>\n",
              "      <th>size_size</th>\n",
              "      <th>n_rooms_n_rooms</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>-0.867295</td>\n",
              "      <td>-0.408907</td>\n",
              "      <td>0.703929</td>\n",
              "      <td>compact</td>\n",
              "      <td>304480.0</td>\n",
              "      <td>0.177597</td>\n",
              "      <td>-0.882698</td>\n",
              "      <td>0.572395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.272945</td>\n",
              "      <td>0.331953</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>economy</td>\n",
              "      <td>607930.0</td>\n",
              "      <td>1.084261</td>\n",
              "      <td>-0.364521</td>\n",
              "      <td>1.605433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>2.104454</td>\n",
              "      <td>2.194115</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>economy</td>\n",
              "      <td>382930.0</td>\n",
              "      <td>2.638541</td>\n",
              "      <td>2.431225</td>\n",
              "      <td>1.605433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.669178</td>\n",
              "      <td>1.112860</td>\n",
              "      <td>-1.402802</td>\n",
              "      <td>standard</td>\n",
              "      <td>57230.0</td>\n",
              "      <td>-1.350778</td>\n",
              "      <td>-0.718006</td>\n",
              "      <td>-1.149335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.669178</td>\n",
              "      <td>-2.010766</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>fullsize</td>\n",
              "      <td>247230.0</td>\n",
              "      <td>-0.806780</td>\n",
              "      <td>-0.718006</td>\n",
              "      <td>-0.804989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>0.321405</td>\n",
              "      <td>-0.509023</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>standard</td>\n",
              "      <td>130860.0</td>\n",
              "      <td>-0.547734</td>\n",
              "      <td>0.225960</td>\n",
              "      <td>-0.804989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Mercaz</td>\n",
              "      <td>-1.065412</td>\n",
              "      <td>0.952674</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>premium</td>\n",
              "      <td>609380.0</td>\n",
              "      <td>-0.910399</td>\n",
              "      <td>-1.039356</td>\n",
              "      <td>-0.804989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Old North</td>\n",
              "      <td>0.321405</td>\n",
              "      <td>-0.028465</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>standard</td>\n",
              "      <td>458980.0</td>\n",
              "      <td>0.125788</td>\n",
              "      <td>0.225960</td>\n",
              "      <td>-0.231079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-1.857878</td>\n",
              "      <td>-0.408907</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>convertible</td>\n",
              "      <td>4505130.0</td>\n",
              "      <td>0.048074</td>\n",
              "      <td>-1.585651</td>\n",
              "      <td>1.605433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>-0.471062</td>\n",
              "      <td>-0.208674</td>\n",
              "      <td>-1.402802</td>\n",
              "      <td>compact</td>\n",
              "      <td>23690.0</td>\n",
              "      <td>-1.324874</td>\n",
              "      <td>-0.545280</td>\n",
              "      <td>-1.149335</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            area      size      lamp  ...  size_n_rooms size_size  n_rooms_n_rooms\n",
              "0     Florentine -0.867295 -0.408907  ...      0.177597 -0.882698         0.572395\n",
              "1      Old North -0.272945  0.331953  ...      1.084261 -0.364521         1.605433\n",
              "2     Florentine  2.104454  2.194115  ...      2.638541  2.431225         1.605433\n",
              "3      Old North -0.669178  1.112860  ...     -1.350778 -0.718006        -1.149335\n",
              "4      Old North -0.669178 -2.010766  ...     -0.806780 -0.718006        -0.804989\n",
              "...          ...       ...       ...  ...           ...       ...              ...\n",
              "9995  Florentine  0.321405 -0.509023  ...     -0.547734  0.225960        -0.804989\n",
              "9996      Mercaz -1.065412  0.952674  ...     -0.910399 -1.039356        -0.804989\n",
              "9997   Old North  0.321405 -0.028465  ...      0.125788  0.225960        -0.231079\n",
              "9998   Old North -1.857878 -0.408907  ...      0.048074 -1.585651         1.605433\n",
              "9999  Florentine -0.471062 -0.208674  ...     -1.324874 -0.545280        -1.149335\n",
              "\n",
              "[10000 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB4j6CGfclCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class EmbeddingMapping():\n",
        "    \"\"\"\n",
        "    Helper class for handling categorical variables\n",
        "    An instance of this class should be defined for each categorical variable we want to use.\n",
        "    \"\"\"\n",
        "    def __init__(self, series):\n",
        "        # get a list of unique values\n",
        "        values = series.unique().tolist()\n",
        "        \n",
        "        # Set a dictionary mapping from values to integer value\n",
        "        # In our example this will be {'Mercaz': 1, 'Old North': 2, 'Florentine': 3}\n",
        "        self.embedding_dict = {value: int_value+1 for int_value, value in enumerate(values)}\n",
        "        \n",
        "        # The num_values will be used as the input_dim when defining the embedding layer. \n",
        "        # It will also be returned for unseen values \n",
        "        self.num_values = len(values) + 1\n",
        "\n",
        "    def get_mapping(self, value):\n",
        "        # If the value was seen in the training set, return its integer mapping\n",
        "        if value in self.embedding_dict:\n",
        "            return self.embedding_dict[value]\n",
        "        \n",
        "        # Else, return the same integer for unseen values\n",
        "        else:\n",
        "            return self.num_values"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VRLho82cnhC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "1453d37e-19bd-49cd-c228-d6650aa53a00"
      },
      "source": [
        "area_mapping = EmbeddingMapping(dataset['area'])\n",
        "type_mapping = EmbeddingMapping(dataset['ctype'])\n",
        "\n",
        "dataset = dataset.assign(area_mapping=dataset['area'].apply(area_mapping.get_mapping))\n",
        "dataset = dataset.assign(type_mapping=dataset['ctype'].apply(type_mapping.get_mapping))\n",
        "dataset"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>size</th>\n",
              "      <th>lamp</th>\n",
              "      <th>n_rooms</th>\n",
              "      <th>ctype</th>\n",
              "      <th>price</th>\n",
              "      <th>size_n_rooms</th>\n",
              "      <th>size_size</th>\n",
              "      <th>n_rooms_n_rooms</th>\n",
              "      <th>area_mapping</th>\n",
              "      <th>type_mapping</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>-0.867295</td>\n",
              "      <td>-0.408907</td>\n",
              "      <td>0.703929</td>\n",
              "      <td>compact</td>\n",
              "      <td>304480.0</td>\n",
              "      <td>0.177597</td>\n",
              "      <td>-0.882698</td>\n",
              "      <td>0.572395</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.272945</td>\n",
              "      <td>0.331953</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>economy</td>\n",
              "      <td>607930.0</td>\n",
              "      <td>1.084261</td>\n",
              "      <td>-0.364521</td>\n",
              "      <td>1.605433</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>2.104454</td>\n",
              "      <td>2.194115</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>economy</td>\n",
              "      <td>382930.0</td>\n",
              "      <td>2.638541</td>\n",
              "      <td>2.431225</td>\n",
              "      <td>1.605433</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.669178</td>\n",
              "      <td>1.112860</td>\n",
              "      <td>-1.402802</td>\n",
              "      <td>standard</td>\n",
              "      <td>57230.0</td>\n",
              "      <td>-1.350778</td>\n",
              "      <td>-0.718006</td>\n",
              "      <td>-1.149335</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-0.669178</td>\n",
              "      <td>-2.010766</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>fullsize</td>\n",
              "      <td>247230.0</td>\n",
              "      <td>-0.806780</td>\n",
              "      <td>-0.718006</td>\n",
              "      <td>-0.804989</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>0.321405</td>\n",
              "      <td>-0.509023</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>standard</td>\n",
              "      <td>130860.0</td>\n",
              "      <td>-0.547734</td>\n",
              "      <td>0.225960</td>\n",
              "      <td>-0.804989</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Mercaz</td>\n",
              "      <td>-1.065412</td>\n",
              "      <td>0.952674</td>\n",
              "      <td>-0.700558</td>\n",
              "      <td>premium</td>\n",
              "      <td>609380.0</td>\n",
              "      <td>-0.910399</td>\n",
              "      <td>-1.039356</td>\n",
              "      <td>-0.804989</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Old North</td>\n",
              "      <td>0.321405</td>\n",
              "      <td>-0.028465</td>\n",
              "      <td>0.001685</td>\n",
              "      <td>standard</td>\n",
              "      <td>458980.0</td>\n",
              "      <td>0.125788</td>\n",
              "      <td>0.225960</td>\n",
              "      <td>-0.231079</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Old North</td>\n",
              "      <td>-1.857878</td>\n",
              "      <td>-0.408907</td>\n",
              "      <td>1.406172</td>\n",
              "      <td>convertible</td>\n",
              "      <td>4505130.0</td>\n",
              "      <td>0.048074</td>\n",
              "      <td>-1.585651</td>\n",
              "      <td>1.605433</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Florentine</td>\n",
              "      <td>-0.471062</td>\n",
              "      <td>-0.208674</td>\n",
              "      <td>-1.402802</td>\n",
              "      <td>compact</td>\n",
              "      <td>23690.0</td>\n",
              "      <td>-1.324874</td>\n",
              "      <td>-0.545280</td>\n",
              "      <td>-1.149335</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 11 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            area      size  ...  area_mapping  type_mapping\n",
              "0     Florentine -0.867295  ...             1             1\n",
              "1      Old North -0.272945  ...             2             2\n",
              "2     Florentine  2.104454  ...             1             2\n",
              "3      Old North -0.669178  ...             2             3\n",
              "4      Old North -0.669178  ...             2             4\n",
              "...          ...       ...  ...           ...           ...\n",
              "9995  Florentine  0.321405  ...             1             3\n",
              "9996      Mercaz -1.065412  ...             3             8\n",
              "9997   Old North  0.321405  ...             2             3\n",
              "9998   Old North -1.857878  ...             2             7\n",
              "9999  Florentine -0.471062  ...             1             1\n",
              "\n",
              "[10000 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lyzeKKVcqOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset과 validationset 나누고... 기타 정리\n",
        "\n",
        "X_train_org, X_val_org, Y_train, Y_val = train_test_split(dataset[['size','lamp','n_rooms','size_n_rooms','size_size','n_rooms_n_rooms','area_mapping','type_mapping']],\n",
        "    dataset['price'], test_size=0.1, random_state=0)\n",
        "\n",
        "\n",
        "X_train_continuous_org = X_train_org[['size','lamp','n_rooms','size_n_rooms','size_size','n_rooms_n_rooms']]\n",
        "X_train_categorical_org = X_train_org[['area_mapping','type_mapping']]\n",
        "X_val_continuous_org = X_val_org[['size','lamp','n_rooms','size_n_rooms','size_size','n_rooms_n_rooms']]\n",
        "X_val_categorical_org = X_val_org[['area_mapping','type_mapping']]\n",
        "\n",
        "# 학습 대상 변수만 선택\n",
        "X_train_continuous = X_train_continuous_org[['size','n_rooms','n_rooms_n_rooms']]\n",
        "X_train_categorical = X_train_categorical_org\n",
        "X_val_continuous  = X_val_continuous_org[['size','n_rooms','n_rooms_n_rooms']]\n",
        "X_val_categorical = X_val_categorical_org\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX0r-hXPcszd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8a522840-f28a-4fb3-e320-d9b5a2a4234e"
      },
      "source": [
        "# Define the embedding input\n",
        "cate_input = Input(shape=(2,), dtype='int32') \n",
        "\n",
        "# Decide to what vector size we want to map our 'area' variable. \n",
        "# I'll use 1 here because we only have three areas\n",
        "embeddings_output = 24*3\n",
        "\n",
        "\n",
        "# Let’s define the embedding layer and flatten it\n",
        "cate_embedings = Embedding(output_dim=embeddings_output, input_dim=10000)(cate_input)\n",
        "cate_embedings = keras.layers.Reshape((embeddings_output*2,))(cate_embedings)\n",
        "print(cate_embedings)\n",
        "# Define the continuous variables input (just like before)\n",
        "continuous_input = Input(shape=(X_train_continuous.shape[1], ))\n",
        "\n",
        "# Concatenate continuous and embeddings inputs\n",
        "all_input = keras.layers.concatenate([continuous_input, cate_embedings])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"reshape_1/Reshape:0\", shape=(None, 144), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tujRczwXczs-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "outputId": "f4bf24bb-38f5-4388-994b-739df3589f6a"
      },
      "source": [
        "# Define the model\n",
        "dense1 = Dense(all_input.shape[1]*3, activation='relu')(all_input)\n",
        "dense2 = Dense(5, activation='relu')(dense1)\n",
        "predictions = Dense(1)(dense2)\n",
        "\n",
        "# Note using the input object 'area_input' not 'area_embeddings'\n",
        "model = Model(inputs=[continuous_input, cate_input], outputs=predictions)\n",
        "model.compile(loss='mse', optimizer=keras.optimizers.Adam(lr=.8, beta_1=0.9, beta_2=0.999, decay=1e-03, amsgrad=True),metrics=[soft_100_acc,soft_300_acc,r2])\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 2)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 2, 72)        720000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 3)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 144)          0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 147)          0           input_2[0][0]                    \n",
            "                                                                 reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 441)          65268       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 5)            2210        dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            6           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 787,484\n",
            "Trainable params: 787,484\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri3VPP6Ac04I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "outputId": "7bf8e536-582f-4c29-d6bb-f925f29d9806"
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "# Note continuous and categorical columns are inserted in the same order as defined in all_inputs\n",
        "history = model.fit([X_train_continuous, X_train_categorical], Y_train, \n",
        "          epochs=epochs, batch_size=128, \n",
        "          callbacks=[periodic_logger_50], verbose=0,\n",
        "          validation_data=([X_val_continuous, X_val_categorical], Y_val))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50 - {'val_loss': 4622512193273.856, 'val_soft_100_acc': 0.0, 'val_soft_300_acc': 0.0, 'val_r2': -0.4605264663696289, 'loss': 4004555675140.096, 'soft_100_acc': 0.0, 'soft_300_acc': 0.0, 'r2': -0.4818077}\n",
            "Epoch: 100 - {'val_loss': 4621432162091.008, 'val_soft_100_acc': 0.0, 'val_soft_300_acc': 0.0, 'val_r2': -0.46015822887420654, 'loss': 4003531746734.535, 'soft_100_acc': 0.0, 'soft_300_acc': 0.0, 'r2': -0.48585108}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-15b32c110d77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperiodic_logger_50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           validation_data=([X_val_continuous, X_val_categorical], Y_val))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fc3AvXydhkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the train/validation loss values\n",
        "plt.figure(figsize=(20,10))\n",
        "_loss = history.history['loss'][250:]\n",
        "_val_loss = history.history['val_loss'][250:]\n",
        "\n",
        "train_loss_plot, = plt.plot(range(1, len(_loss)+1), _loss, label='Train Loss')\n",
        "val_loss_plot, = plt.plot(range(1, len(_val_loss)+1), _val_loss, label='Validation Loss')\n",
        "\n",
        "_ = plt.legend(handles=[train_loss_plot, val_loss_plot])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTft1wLZdlUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(Y_val,columns=['price'])\n",
        "\n",
        "print (\"This is the average value we are trying to predict: %d\" % df['price'].mean())\n",
        "\n",
        "# Add a column for the model's predicted values\n",
        "df['pred'] = model.predict([X_val_continuous, X_val_categorical])\n",
        "\n",
        "# Calculate the difference between the predicted and the actual price\n",
        "df['diff'] = df['pred'] - df['price']\n",
        "\n",
        "# Calculate the absolute difference between the predicted and the actual price\n",
        "df['abs_diff'] = np.abs(df['diff'])\n",
        "\n",
        "# Calculate the percentage of the difference from the actual price\n",
        "df['%diff'] = 100 * (df['diff'] / df['price'])\n",
        "\n",
        "# Calculate the absolute percentage difference from the actual price\n",
        "df['abs_%diff'] = np.abs(df['%diff'])\n",
        "\n",
        "# Sort by the 'abs_diff' field and show the 5 largest mistakes in absolute values\n",
        "print(df.sort_values(\"abs_diff\", ascending=False).head(5))\n",
        "# Calculate the mean and std. of the diff field\n",
        "diff_mean, diff_std = df['diff'].mean(), df['diff'].std()\n",
        "print(\"The mean is very close to 0 ({mean}) with std. {std}.\".format(mean=round(diff_mean, 2), std=round(diff_std, 2)))\n",
        "\n",
        "# Here is the histogram of the differences\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(df['diff'], bins=100)\n",
        "plt.xlabel(\"$\")\n",
        "plt.ylabel(\"# samples\")\n",
        "_ = plt.title(\"Difference between predicted and actual price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkhKoSindpu6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort by the '%diff' field and show the 5 largest proportional mistakes\n",
        "print(df.sort_values(\"abs_%diff\", ascending=False).head(5))\n",
        "\n",
        "# Also, plot the histogram\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(df['%diff'], bins=100)\n",
        "plt.xlabel(\"%\")\n",
        "plt.ylabel(\"# samples\")\n",
        "_ = plt.title(\"% of difference between predicted and actual price\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfWvOO-7d88p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = pd.concat([X_train_continuous,X_train_categorical], axis=1)\n",
        "val_ds = pd.concat([X_val_continuous,X_val_categorical], axis=1)\n",
        "\n",
        "# XAI를 위한 lime  정의\n",
        "from lime import lime_tabular, lime_text\n",
        "exp = lime_tabular.LimeTabularExplainer(\n",
        "    train_ds.to_numpy(),\n",
        "    training_labels=Y_train,\n",
        "    feature_names=train_ds.columns,\n",
        "    class_names= ['price'],\n",
        "    mode=\"regression\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46tqAKwNfonk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 변수의 영향력 분석\n",
        "# 소팅을 위한 초기화 \n",
        "exp_ana = {}\n",
        "for k in train_ds.columns:\n",
        "  exp_ana[k] = 0\n",
        "\n",
        "# predict 함수 재정의 - lime에서 사용 가능하도록...\n",
        "continue_dim = X_train_continuous.shape[1]\n",
        "input_dim = train_ds.shape[1]\n",
        "def predict(data):\n",
        "    return model.predict([data[:,0:continue_dim],data[:,continue_dim:input_dim]])\n",
        "\n",
        "# validation set의 변수 영향력 분석...\n",
        "for i in range(40): #range(val_ds.shape[0]):\n",
        "    p = exp.explain_instance(np.asarray(val_ds.iloc[i]),predict,num_features=val_ds.shape[1])\n",
        "    for t in p.as_map()[0]:\n",
        "      exp_ana[train_ds.columns[t[0]]] += np.abs(t[1])\n",
        "\n",
        "import operator\n",
        "\n",
        "sorted_x = sorted(exp_ana.items(), key=operator.itemgetter(1))\n",
        "\n",
        "effect_result_table = pd.DataFrame(sorted_x,columns=['Feature', 'Effect'] )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLhbbhyefr4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "effect_result_table['Effect'] = effect_result_table['Effect']/10000\n",
        "effect_result_table.plot(x='Feature',y='Effect',kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jTRsG4n1fwUz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structure(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGGj2kCthMm8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_area_mapping = pd.DataFrame(to_categorical(dataset['area_mapping']-1),columns=['area_' + s for s in AREAS])\n",
        "dataset_type_mapping = pd.DataFrame(to_categorical(dataset['type_mapping']-1),columns=['type_' + s for s in HOUSE_TYPE])\n",
        "dataset = pd.concat([dataset,dataset_area_mapping,dataset_type_mapping], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIaht8Ooh4Cy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structure(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vFDWq5eimgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKoENoiSj0Kz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#  추가 파생변수 생성\n",
        "dataset_size_area_mapping = dataset[['area_' + s for s in AREAS]].multiply(dataset['size'], axis=0)\n",
        "dataset_n_rooms_area_mapping = dataset[['area_' + s for s in AREAS]].multiply(dataset['n_rooms'], axis=0)\n",
        "dataset_size_area_mapping.rename(columns={'area_' + s:'size_area_'+s for s in AREAS}, inplace=True)\n",
        "dataset_n_rooms_area_mapping.rename(columns={'area_' + s:'n_rooms_area_'+s for s in AREAS}, inplace=True)\n",
        "\n",
        "dataset_size_type_mapping = dataset[['type_' + s for s in HOUSE_TYPE]].multiply(dataset['size'], axis=0)\n",
        "dataset_n_rooms_type_mapping = dataset[['type_' + s for s in HOUSE_TYPE]].multiply(dataset['n_rooms'], axis=0)\n",
        "dataset_size_type_mapping.rename(columns={'type_' + s:'size_type_'+s for s in HOUSE_TYPE}, inplace=True)\n",
        "dataset_n_rooms_type_mapping.rename(columns={'type_' + s:'n_rooms_type_'+s for s in HOUSE_TYPE}, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAAiF8RSk27X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.concat([dataset,dataset_size_area_mapping,dataset_n_rooms_area_mapping,dataset_size_type_mapping,dataset_n_rooms_type_mapping], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoRG0yAnlFTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "structure(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qNrTzB4kaaq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQfQfuCYmTAI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# trainset과 validationset 나누고... 기타 정리\n",
        "\n",
        "columns = list(dataset.columns)\n",
        "for a in ['area','ctype','lamp','price','size_n_rooms','size_size']:\n",
        "  columns.remove(a)\n",
        "\n",
        "X_train_org, X_val_org, Y_train, Y_val = train_test_split(dataset[columns],\n",
        "    dataset['price'], test_size=0.1, random_state=0)\n",
        "\n",
        "columns.remove('area_mapping')\n",
        "columns.remove('type_mapping')\n",
        "\n",
        "X_train_continuous = X_train_org[columns]\n",
        "X_train_categorical = X_train_org[['area_mapping','type_mapping']]\n",
        "X_val_continuous = X_val_org[columns]\n",
        "X_val_categorical = X_val_org[['area_mapping','type_mapping']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAK1YvTwo7bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the embedding input\n",
        "cate_input = Input(shape=(2,), dtype='int32') \n",
        "\n",
        "# Decide to what vector size we want to map our 'area' variable. \n",
        "# I'll use 1 here because we only have three areas\n",
        "embeddings_output = 24*3\n",
        "\n",
        "\n",
        "# Let’s define the embedding layer and flatten it\n",
        "cate_embedings = Embedding(output_dim=embeddings_output, input_dim=10000)(cate_input)\n",
        "cate_embedings = keras.layers.Reshape((embeddings_output*2,))(cate_embedings)\n",
        "\n",
        "# Define the continuous variables input (just like before)\n",
        "continuous_input = Input(shape=(X_train_continuous.shape[1], ))\n",
        "\n",
        "# Concatenate continuous and embeddings inputs\n",
        "all_input = keras.layers.concatenate([continuous_input, cate_embedings])\n",
        "\n",
        "print(all_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjH9K6Y6p1zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " def mean_squared_error(y_true, y_pred):\n",
        "     return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "\n",
        "# Define the model\n",
        "dense1 = Dense(all_input.shape[1]*3, activation='relu')(all_input)\n",
        "dense2 = Dense(5, activation='relu')(dense1)\n",
        "predictions = Dense(1,)(dense2)\n",
        "\n",
        "# Note using the input object 'area_input' not 'area_embeddings'\n",
        "model = Model(inputs=[continuous_input, cate_input], outputs=predictions)\n",
        "model.compile(loss=mean_squared_error, optimizer=keras.optimizers.Adam(lr=.8, beta_1=0.9, beta_2=0.999, decay=1e-03, amsgrad=True),metrics=[soft_100_acc,soft_300_acc,r2])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9o8eYjTvp9AN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 1000\n",
        "\n",
        "# Note continuous and categorical columns are inserted in the same order as defined in all_inputs\n",
        "history = model.fit([X_train_continuous,X_train_categorical], Y_train, \n",
        "          epochs=epochs, batch_size=128, \n",
        "          callbacks=[periodic_logger_50], verbose=0,\n",
        "          validation_data=([X_val_continuous,X_val_categorical], Y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od7tb3xYyoFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot the train/validation loss values\n",
        "plt.figure(figsize=(20,10))\n",
        "_loss = history.history['loss'][250:]\n",
        "_val_loss = history.history['val_loss'][250:]\n",
        "\n",
        "train_loss_plot, = plt.plot(range(1, len(_loss)+1), _loss, label='Train Loss')\n",
        "val_loss_plot, = plt.plot(range(1, len(_val_loss)+1), _val_loss, label='Validation Loss')\n",
        "\n",
        "_ = plt.legend(handles=[train_loss_plot, val_loss_plot])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lqpxHFC5rFv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(Y_val,columns=['price'])\n",
        "\n",
        "print (\"This is the average value we are trying to predict: %d\" % df['price'].mean())\n",
        "\n",
        "# Add a column for the model's predicted values\n",
        "df['pred'] = model.predict([X_val_continuous, X_val_categorical])\n",
        "\n",
        "# Calculate the difference between the predicted and the actual price\n",
        "df['diff'] = df['pred'] - df['price']\n",
        "\n",
        "# Calculate the absolute difference between the predicted and the actual price\n",
        "df['abs_diff'] = np.abs(df['diff'])\n",
        "\n",
        "# Calculate the percentage of the difference from the actual price\n",
        "df['%diff'] = 100 * (df['diff'] / df['price'])\n",
        "\n",
        "# Calculate the absolute percentage difference from the actual price\n",
        "df['abs_%diff'] = np.abs(df['%diff'])\n",
        "\n",
        "# Calculate the mean and std. of the diff field\n",
        "diff_mean, diff_std = df['diff'].mean(), df['diff'].std()\n",
        "print(\"The mean is very close to 0 ({mean}) with std. {std}.\".format(mean=round(diff_mean, 2), std=round(diff_std, 2)))\n",
        "\n",
        "# Here is the histogram of the differences\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.hist(df['diff'], bins=100)\n",
        "plt.xlabel(\"$\")\n",
        "plt.ylabel(\"# samples\")\n",
        "_ = plt.title(\"Difference between predicted and actual price\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Sort by the 'abs_diff' field and show the 5 largest mistakes in absolute values\n",
        "a = df.sort_values(\"abs_diff\", ascending=False)\n",
        "a.drop(columns=['price'],inplace=True)\n",
        "b = a.join(dataset)\n",
        "b.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxKFNviabQle",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds = pd.concat([X_train_continuous,X_train_categorical], axis=1)\n",
        "val_ds = pd.concat([X_val_continuous,X_val_categorical], axis=1)\n",
        "\n",
        "# XAI를 위한 lime  정의\n",
        "from lime import lime_tabular, lime_text\n",
        "exp = lime_tabular.LimeTabularExplainer(\n",
        "    train_ds.to_numpy(),\n",
        "    training_labels=Y_train,\n",
        "    feature_names=train_ds.columns,\n",
        "    class_names= ['price'],\n",
        "    mode=\"regression\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}